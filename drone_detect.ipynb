{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üõ∏ Drohnen-Detektion in Drohnen‚ÄëVideos mit **YOLOv8** (Google Colab)\n",
        "**Super‚Äëkommentierte Schritt‚Äëf√ºr‚ÄëSchritt‚ÄëAnleitung** f√ºr 5.‚ÄëSemester‚ÄëStudis: Installation ‚Üí Datenaufbereitung (Frames + 640√ó640‚ÄëKacheln) ‚Üí Training ‚Üí Evaluation ‚Üí Inference (inkl. **tiled inference** f√ºr 4K‚ÄëVideos) ‚Üí Export zur√ºck in Google Drive.\n",
        "\n",
        "> **Tipp:** In Colab unter *Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU* eine GPU w√§hlen (T4/A100).  \n",
        "> Diese Notebook‚ÄëVersion generiert keine synthetischen Daten; f√ºr Annotationen (Labels) nutzt bitte Tools wie **CVAT**, **Label Studio** oder **Roboflow Annotate** und exportiert im **YOLO‚ÄëTXT‚ÄëFormat**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Quick Start (√úberblick)\n",
        "1. **Installieren** (`ultralytics`, `opencv-python`, `ffmpeg`)  \n",
        "2. **Google Drive mounten** und Pfade setzen  \n",
        "3. **Videos aus Drive einbinden** ‚Üí `raw_videos/`  \n",
        "4. **Frames extrahieren** (z.‚ÄØB. 2‚ÄØFPS)  \n",
        "5. **In 640√ó640 kacheln** (20‚ÄØ% √úberlappung)  \n",
        "6. **Kacheln labeln** (extern), Labels ins Projekt kopieren  \n",
        "7. **Datensatz (train/val/test) bauen** + `data.yaml`  \n",
        "8. **YOLOv8 trainieren** und **validieren**  \n",
        "9. **Inference** (einfach & tiled f√ºr 4K)  \n",
        "10. **Ergebnisse nach Drive sichern**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0Ô∏è‚É£ Umgebung pr√ºfen (GPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "575da157",
      "metadata": {},
      "source": [
        "pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: 3.13.2\n",
            "PyTorch: 2.9.1+cpu\n",
            "CUDA verf√ºgbar: False\n",
            "‚ö†Ô∏è Keine GPU aktiv. CPU funktioniert auch, ist aber langsamer. In Colab ggf. GPU aktivieren (Runtime ‚Üí Change runtime type).\n"
          ]
        }
      ],
      "source": [
        "# !nvidia-smi || true\n",
        "\n",
        "import torch, platform, sys\n",
        "print(\"Python:\", sys.version.split()[0])\n",
        "print(\"PyTorch:\", torch.__version__)\n",
        "print(\"CUDA verf√ºgbar:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA Ger√§t:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Keine GPU aktiv. CPU funktioniert auch, ist aber langsamer. In Colab ggf. GPU aktivieren (Runtime ‚Üí Change runtime type).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£ Installation (YOLOv8 + Tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dca783f",
      "metadata": {},
      "source": [
        "pip install ultralytics opencv-python tqdm numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'apt-get' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pfad zu 'yolo': C:\\Users\\Ignaz\\.conda\\envs\\Schmetterling\\Scripts\\yolo.EXE\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'apt-get' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!pip -q install ultralytics opencv-python tqdm numpy matplotlib\n",
        "!apt-get -qq update\n",
        "!apt-get -qq install -y ffmpeg\n",
        "\n",
        "import shutil\n",
        "print(\"Pfad zu 'yolo':\", shutil.which(\"yolo\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file  \n",
            "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\Ignaz\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "ultralytics: 8.3.229\n",
            "opencv: 4.12.0\n"
          ]
        }
      ],
      "source": [
        "import os, glob, math, shutil, subprocess, random, json, textwrap, time\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print(\"ultralytics:\", ultralytics.__version__)\n",
        "print(\"opencv:\", cv2.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2Ô∏è‚É£ Google Drive mounten & Projektpfade setzen\n",
        "- Legt eure Videos in Drive z.‚ÄØB. unter: `MyDrive/datasets/drone_videos`  \n",
        "- **Anpassen:** `GDRIVE_VIDEOS_DIR` unten ggf. auf euren Pfad √§ndern."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6f051cc",
      "metadata": {},
      "source": [
        "google drive eig. nicht mehr n√∂tig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Projektordner: ../Schmetterlingsverfolgung\n",
            "Drive Videos: /datasets/drone_videos/\n",
            "Drive Export: /drone_yolo8_runs/\n"
          ]
        }
      ],
      "source": [
        "GDRIVE_VIDEOS_DIR = \"/datasets/drone_videos/\"\n",
        "DRIVE_EXPORT_DIR  = \"/drone_yolo8_runs/\"\n",
        "\n",
        "PROJ_ROOT   = \"../Schmetterlingsverfolgung\"\n",
        "RAW_VIDEOS  = f\"{PROJ_ROOT}/raw_videos\"\n",
        "FRAMES_RAW  = f\"{PROJ_ROOT}/frames_raw\"\n",
        "FRAMES_TILES= f\"{PROJ_ROOT}/frames_tiles\"\n",
        "ANNOTATIONS = f\"{PROJ_ROOT}/annotations\"\n",
        "DATASET     = f\"{PROJ_ROOT}/datasets\"\n",
        "TOOLS       = f\"{PROJ_ROOT}/tools\"\n",
        "\n",
        "for p in [\n",
        "    PROJ_ROOT, RAW_VIDEOS, FRAMES_RAW, FRAMES_TILES, ANNOTATIONS, DATASET,\n",
        "    f\"{DATASET}/images/train\", f\"{DATASET}/images/val\", f\"{DATASET}/images/test\",\n",
        "    f\"{DATASET}/labels/train\", f\"{DATASET}/labels/val\", f\"{DATASET}/labels/test\",\n",
        "    DRIVE_EXPORT_DIR, TOOLS\n",
        "]:\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "print(\"Projektordner:\", PROJ_ROOT)\n",
        "print(\"Drive Videos:\", GDRIVE_VIDEOS_DIR)\n",
        "print(\"Drive Export:\", DRIVE_EXPORT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3Ô∏è‚É£ Videos aus Google Drive einbinden\n",
        "- Standard: **Symlink** (spart Speicher). Fallback: **Copy**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gefundene Videos in Drive: 0\n",
            "Videos im Projekt: 2\n"
          ]
        }
      ],
      "source": [
        "def collect_videos(src_dir: str, dst_dir: str) -> list:\n",
        "    exts = (\"*.MP4\",\"*.mov\",\"*.mkv\",\"*.avi\",\"*.m4v\")\n",
        "    videos = []\n",
        "    for e in exts:\n",
        "        videos.extend(glob.glob(os.path.join(src_dir, e)))\n",
        "    videos = sorted(videos)\n",
        "    print(f\"Gefundene Videos in Drive: {len(videos)}\")\n",
        "    for v in videos[:5]:\n",
        "        print(\"  ‚Ä¢\", os.path.basename(v))\n",
        "    for v in videos:\n",
        "        name = os.path.basename(v)\n",
        "        dst = os.path.join(dst_dir, name)\n",
        "        if os.path.exists(dst):\n",
        "            continue\n",
        "        try:\n",
        "            os.symlink(v, dst)\n",
        "            mode = \"link\"\n",
        "        except Exception:\n",
        "            shutil.copy2(v, dst)\n",
        "            mode = \"copy\"\n",
        "        print(f\"{mode:4s} ‚Üí {name}\")\n",
        "    return sorted(glob.glob(os.path.join(dst_dir, \"*\")))\n",
        "\n",
        "videos_local = collect_videos(GDRIVE_VIDEOS_DIR, RAW_VIDEOS)\n",
        "print(\"Videos im Projekt:\", len(videos_local))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4Ô∏è‚É£ Frames aus Videos extrahieren (sparsam samplen)\n",
        "- Empfehlung: **2 FPS** (anpassbar √ºber `FPS`)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fa5b1ef",
      "metadata": {},
      "source": [
        "conda install -c conda-forge ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FFmpeg: ffmpeg -y -i ..\\Schmetterlingsverfolgung\\raw_videos\\DJI_0519.MP4 -vf fps=2 ..\\Schmetterlingsverfolgung\\frames_raw\\DJI_0519\\frame_%06d.jpg\n",
            "FFmpeg: ffmpeg -y -i ..\\Schmetterlingsverfolgung\\raw_videos\\DJI_0521.MP4 -vf fps=2 ..\\Schmetterlingsverfolgung\\frames_raw\\DJI_0521\\frame_%06d.jpg\n",
            "Ordner mit Frames: 2\n",
            "Gesamtzahl Frames: 27\n"
          ]
        }
      ],
      "source": [
        "FPS = 2\n",
        "\n",
        "def extract_frames(video_path: str, out_dir: str, fps: int = 2):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    # Pfade bereinigen\n",
        "    video_path = os.path.normpath(video_path)\n",
        "    out_dir = os.path.normpath(out_dir)\n",
        "    out_pattern = os.path.normpath(os.path.join(out_dir, \"frame_%06d.jpg\"))\n",
        "\n",
        "\n",
        "    out_pattern = os.path.join(out_dir, \"frame_%06d.jpg\")\n",
        "    cmd = [\"ffmpeg\", \"-y\", \"-i\", video_path, \"-vf\", f\"fps={fps}\", out_pattern]\n",
        "    print(\"FFmpeg:\", \" \".join(cmd))\n",
        "    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    if result.returncode != 0:\n",
        "        print(\"‚ö†Ô∏è FFmpeg Fehler:\", result.stderr[:2000])\n",
        "\n",
        "for vp in videos_local:\n",
        "    base = os.path.splitext(os.path.basename(vp))[0]\n",
        "    out = os.path.join(FRAMES_RAW, base)\n",
        "    if len(glob.glob(os.path.join(out, \"*.jpg\"))) > 0:\n",
        "        print(\"Skip (bereits extrahiert):\", base)\n",
        "        continue\n",
        "    extract_frames(vp, out, FPS)\n",
        "\n",
        "folders = sorted([d for d in glob.glob(os.path.join(FRAMES_RAW, \"*\")) if os.path.isdir(d)])\n",
        "total_frames = sum(len(glob.glob(os.path.join(d, \"*.jpg\"))) for d in folders)\n",
        "print(\"Ordner mit Frames:\", len(folders))\n",
        "print(\"Gesamtzahl Frames:\", total_frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5Ô∏è‚É£ 4K‚ÄëFrames in **640√ó640‚ÄëKacheln** schneiden (+ √úberlappung)\n",
        "**Empfehlung:** `TILE_SIZE = 640`, `OVERLAP = 0.2` (20‚ÄØ%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kacheln: DJI_0519  (Frames: 12)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00, 11.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kacheln: DJI_0521  (Frames: 15)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  8.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gesamtzahl Kacheln: 864\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "TILE_SIZE = 640\n",
        "OVERLAP   = 0.20\n",
        "JPEG_QUALITY = 95\n",
        "\n",
        "from typing import List, Tuple\n",
        "\n",
        "def make_grid_coords(w: int, h: int, tile: int, overlap: float) -> Tuple[List[int], List[int]]:\n",
        "    stride = int(tile * (1 - overlap))\n",
        "    xs = list(range(0, max(w - tile, 0) + 1, stride))\n",
        "    ys = list(range(0, max(h - tile, 0) + 1, stride))\n",
        "    if xs[-1] != w - tile: xs.append(max(w - tile, 0))\n",
        "    if ys[-1] != h - tile: ys.append(max(h - tile, 0))\n",
        "    return xs, ys\n",
        "\n",
        "def tile_image(img_path: str, dst_dir: str, tile: int = 640, overlap: float = 0.2) -> int:\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        return 0\n",
        "    h, w = img.shape[:2]\n",
        "    xs, ys = make_grid_coords(w, h, tile, overlap)\n",
        "    base = os.path.splitext(os.path.basename(img_path))[0]\n",
        "    sub  = os.path.basename(os.path.dirname(img_path))\n",
        "    out_dir = os.path.join(dst_dir, sub)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    count = 0\n",
        "    for y in ys:\n",
        "        for x in xs:\n",
        "            tile_img = img[y:y+tile, x:x+tile]\n",
        "            out_name = f\"{base}_x{x}_y{y}.jpg\"\n",
        "            out_path = os.path.join(out_dir, out_name)\n",
        "            cv2.imwrite(out_path, tile_img, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "total_tiles = 0\n",
        "frame_folders = sorted([d for d in glob.glob(os.path.join(FRAMES_RAW, \"*\")) if os.path.isdir(d)])\n",
        "for folder in frame_folders:\n",
        "    frames = sorted(glob.glob(os.path.join(folder, \"*.jpg\")))\n",
        "    print(f\"Kacheln: {os.path.basename(folder)}  (Frames: {len(frames)})\")\n",
        "    for p in tqdm(frames, ncols=100):\n",
        "        total_tiles += tile_image(p, FRAMES_TILES, TILE_SIZE, OVERLAP)\n",
        "\n",
        "print(\"Gesamtzahl Kacheln:\", total_tiles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6Ô∏è‚É£ **Annotieren (Labels zeichnen)** ‚Äì au√üerhalb von Colab\n",
        "1. Tool w√§hlen: **CVAT**, **Label Studio** oder **Roboflow Annotate**.  \n",
        "2. **Kacheln** aus `frames_tiles/` importieren.  \n",
        "3. Klassen: f√ºr den Anfang nur **`0 drone`**.  \n",
        "4. Export im **YOLO‚ÄëTXT‚ÄëFormat** (eine `.txt` pro Bild).  \n",
        "5. **`.txt`** in **`ANNOTATIONS`** kopieren (Basisname muss exakt zum Bild passen)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7Ô∏è‚É£ Labels √ºberpr√ºfen (Abdeckung & Konsistenz)\n",
        "- Z√§hlt, wie viele Bilder **mit / ohne** Label vorhanden sind.  \n",
        "- Optional: F√ºr fehlende Labels leere Dateien anlegen (negative Beispiele)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ALLOW_EMPTY_LABELS = True\n",
        "\n",
        "tile_imgs = sorted(glob.glob(f\"{FRAMES_TILES}/**/*.jpg\", recursive=True))\n",
        "print(\"Anzahl Kachel-Bilder:\", len(tile_imgs))\n",
        "\n",
        "missing = 0\n",
        "nonempty = 0\n",
        "total_labels = 0\n",
        "for img in tile_imgs:\n",
        "    base = os.path.splitext(os.path.basename(img))[0]\n",
        "    lbl = os.path.join(ANNOTATIONS, base + \".txt\")\n",
        "    if not os.path.exists(lbl):\n",
        "        missing += 1\n",
        "        if ALLOW_EMPTY_LABELS:\n",
        "            open(lbl, \"w\").close()\n",
        "    else:\n",
        "        with open(lbl, \"r\") as f:\n",
        "            lines = [ln.strip() for ln in f.readlines() if ln.strip()]\n",
        "            if len(lines) > 0:\n",
        "                nonempty += 1\n",
        "                total_labels += len(lines)\n",
        "\n",
        "print(f\"Fehlende Labels (vor ggf. Erstellen leerer Dateien): {missing}\")\n",
        "print(f\"Bilder mit >=1 Labelzeile: {nonempty}\")\n",
        "print(f\"Summe aller Labelzeilen: {total_labels}\")\n",
        "if ALLOW_EMPTY_LABELS:\n",
        "    now_missing = sum(1 for img in tile_imgs if not os.path.exists(os.path.join(ANNOTATIONS, os.path.splitext(os.path.basename(img))[0] + '.txt')))\n",
        "    print(f\"Fehlende Labels (nach Anlegen leerer Dateien): {now_missing}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8Ô∏è‚É£ Datensatz bauen: **train/val/test** + `data.yaml`\n",
        "- Standard Split: **80‚ÄØ% / 10‚ÄØ% / 10‚ÄØ%**. Negative Beispiele werden behalten."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(0)\n",
        "SPLITS = {\"train\": 0.8, \"val\": 0.1, \"test\": 0.1}\n",
        "\n",
        "for s in [\"images/train\",\"images/val\",\"images/test\",\"labels/train\",\"labels/val\",\"labels/test\"]:\n",
        "    p = os.path.join(DATASET, s)\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "all_imgs = tile_imgs.copy()\n",
        "random.shuffle(all_imgs)\n",
        "n = len(all_imgs)\n",
        "n_train = int(n * SPLITS[\"train\"])\n",
        "n_val   = int(n * SPLITS[\"val\"])\n",
        "train_imgs = all_imgs[:n_train]\n",
        "val_imgs   = all_imgs[n_train:n_train+n_val]\n",
        "test_imgs  = all_imgs[n_train+n_val:]\n",
        "\n",
        "def copy_pair(img_list, split):\n",
        "    for img in img_list:\n",
        "        base = os.path.splitext(os.path.basename(img))[0]\n",
        "        lbl  = os.path.join(ANNOTATIONS, base + \".txt\")\n",
        "        if not os.path.exists(lbl):\n",
        "            if ALLOW_EMPTY_LABELS:\n",
        "                open(lbl, \"w\").close()\n",
        "            else:\n",
        "                continue\n",
        "        shutil.copy2(img, os.path.join(DATASET, f\"images/{split}\", os.path.basename(img)))\n",
        "        shutil.copy2(lbl, os.path.join(DATASET, f\"labels/{split}\", base + \".txt\"))\n",
        "\n",
        "copy_pair(train_imgs, \"train\")\n",
        "copy_pair(val_imgs,   \"val\")\n",
        "copy_pair(test_imgs,  \"test\")\n",
        "\n",
        "print(\"Split Gr√∂√üen:\")\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    ni = len(glob.glob(os.path.join(DATASET, f\"images/{split}/*.jpg\")))\n",
        "    nl = len(glob.glob(os.path.join(DATASET, f\"labels/{split}/*.txt\")))\n",
        "    print(f\"  {split:5s}  imgs={ni:6d}  labels={nl:6d}\")\n",
        "\n",
        "DATA_YAML = os.path.join(PROJ_ROOT, \"data.yaml\")\n",
        "data_yaml_text = f\\\"\\\"\\\"# YOLOv8 data.yaml (auto-generated)\n",
        "path: {DATASET}\n",
        "train: images/train\n",
        "val: images/val\n",
        "test: images/test\n",
        "\n",
        "names:\n",
        "  0: drone\n",
        "\\\"\\\"\\\"\n",
        "with open(DATA_YAML, \"w\") as f:\n",
        "    f.write(data_yaml_text)\n",
        "\n",
        "print(\"data.yaml gespeichert:\", DATA_YAML)\n",
        "print(\"\\\\n--- data.yaml ---\\\\n\", data_yaml_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9Ô∏è‚É£ Visueller Sanity‚ÄëCheck (ein paar Beispiele zeichnen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_yolo_labels(lbl_path: str, img_w: int, img_h: int):\n",
        "    boxes = []\n",
        "    if not os.path.exists(lbl_path):\n",
        "        return boxes\n",
        "    with open(lbl_path, \"r\") as f:\n",
        "        for ln in f:\n",
        "            ln = ln.strip()\n",
        "            if not ln:\n",
        "                continue\n",
        "            parts = ln.split()\n",
        "            if len(parts) != 5 and len(parts) != 6:\n",
        "                continue\n",
        "            cls = int(float(parts[0]))\n",
        "            cx, cy, w, h = map(float, parts[1:5])\n",
        "            x1 = int((cx - w/2) * img_w); y1 = int((cy - h/2) * img_h)\n",
        "            x2 = int((cx + w/2) * img_w); y2 = int((cy + h/2) * img_h)\n",
        "            boxes.append((cls, x1, y1, x2, y2))\n",
        "    return boxes\n",
        "\n",
        "def show_random_samples(split=\"train\", num=4):\n",
        "    imgs = glob.glob(os.path.join(DATASET, f\"images/{split}/*.jpg\"))\n",
        "    random.shuffle(imgs); imgs = imgs[:num]\n",
        "    for p in imgs:\n",
        "        img = cv2.imread(p)\n",
        "        if img is None: continue\n",
        "        h, w = img.shape[:2]\n",
        "        base = os.path.splitext(os.path.basename(p))[0]\n",
        "        lblp = os.path.join(DATASET, f\"labels/{split}/{base}.txt\")\n",
        "        boxes = load_yolo_labels(lblp, w, h)\n",
        "        vis = img.copy()\n",
        "        for cls, x1, y1, x2, y2 in boxes:\n",
        "            cv2.rectangle(vis, (x1,y1), (x2,y2), (0,255,0), 2)\n",
        "            cv2.putText(vis, f\"drone\", (x1, max(0,y1-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
        "        plt.figure(); plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)); plt.title(os.path.basename(p)); plt.axis('off')\n",
        "\n",
        "show_random_samples(\"train\", num=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîü Training mit YOLOv8\n",
        "- Standard: **CLI** (`yolo task=detect ...`)  \n",
        "- Fallback: **Python‚ÄëAPI**, falls CLI fehlt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCHS = 100\n",
        "IMGSZ  = 640\n",
        "BATCH  = 16\n",
        "\n",
        "def latest_run_dir():\n",
        "    runs = sorted(glob.glob(\"/content/runs/detect/train*\"), key=os.path.getmtime)\n",
        "    return runs[-1] if runs else None\n",
        "\n",
        "import shutil, torch, os\n",
        "yolo_cli = shutil.which(\"yolo\")\n",
        "if yolo_cli:\n",
        "    device_arg = \" device=0\" if torch.cuda.is_available() else \"\"\n",
        "    cmd = f\"yolo task=detect mode=train model=yolov8n.pt data={DATA_YAML} epochs={EPOCHS} imgsz={IMGSZ} batch={BATCH}{device_arg}\"\n",
        "    print(\"CLI:\", cmd)\n",
        "    exit_code = os.system(cmd)\n",
        "    if exit_code != 0:\n",
        "        print(\"‚ö†Ô∏è CLI fehlgeschlagen. Fallback: Python-API\")\n",
        "        yolo_cli = None\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è 'yolo' CLI nicht gefunden. Verwende Python-API.\")\n",
        "\n",
        "if not yolo_cli:\n",
        "    model = YOLO(\"yolov8n.pt\")\n",
        "    results = model.train(\n",
        "        data=DATA_YAML,\n",
        "        epochs=EPOCHS,\n",
        "        imgsz=IMGSZ,\n",
        "        batch=BATCH,\n",
        "        device=0 if torch.cuda.is_available() else \"cpu\",\n",
        "    )\n",
        "\n",
        "run_dir = latest_run_dir()\n",
        "print(\"Aktueller Run-Ordner:\", run_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£1Ô∏è‚É£ Validierung (mAP, Precision, Recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_best_weights():\n",
        "    runs = sorted(glob.glob(\"/content/runs/detect/train*\"), key=os.path.getmtime)\n",
        "    for r in reversed(runs):\n",
        "        p = os.path.join(r, \"weights\", \"best.pt\")\n",
        "        if os.path.exists(p):\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "best_weights = find_best_weights()\n",
        "print(\"Best Weights:\", best_weights)\n",
        "\n",
        "if best_weights:\n",
        "    if shutil.which(\"yolo\"):\n",
        "        cmd = f\"yolo task=detect mode=val model='{best_weights}' data={DATA_YAML} imgsz={IMGSZ}\"\n",
        "        print(\"CLI:\", cmd); os.system(cmd)\n",
        "    else:\n",
        "        model = YOLO(best_weights)\n",
        "        metrics = model.val(data=DATA_YAML, imgsz=IMGSZ)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Keine Weights gefunden.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£2Ô∏è‚É£ Trainingskurven ansehen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_training_curves(run_dir: str):\n",
        "    csv_path = os.path.join(run_dir, \"results.csv\")\n",
        "    if not os.path.exists(csv_path):\n",
        "        print(\"‚ö†Ô∏è results.csv nicht gefunden:\", csv_path); return\n",
        "    import csv, numpy as np, matplotlib.pyplot as plt\n",
        "    cols = {}\n",
        "    with open(csv_path, \"r\") as f:\n",
        "        reader = csv.DictReader(f); rows = list(reader)\n",
        "        if not rows: print(\"‚ö†Ô∏è results.csv leer\"); return\n",
        "        keys = reader.fieldnames\n",
        "        for k in keys:\n",
        "            cols[k] = [float(r[k]) if r[k] != \"\" else np.nan for r in rows]\n",
        "    for key in [\"train/box_loss\",\"train/cls_loss\",\"metrics/mAP50(B)\",\"metrics/mAP50-95(B)\"]:\n",
        "        if key in cols:\n",
        "            plt.figure(); plt.plot(cols[key]); plt.title(key); plt.xlabel(\"epoch\"); plt.ylabel(key.split(\"/\")[-1]); plt.grid(True)\n",
        "\n",
        "runs = sorted(glob.glob(\"/content/runs/detect/train*\"), key=os.path.getmtime)\n",
        "if runs:\n",
        "    run_dir = runs[-1]; print(\"Plot aus:\", run_dir); plot_training_curves(run_dir)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Kein Trainingslauf gefunden.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£3Ô∏è‚É£ Inference (einfach): Bilder & Videos\n",
        "F√ºr 4K oder sehr kleine Objekte ‚Üí **tiled inference** nutzen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CONF = 0.25\n",
        "VID_STRIDE = 2\n",
        "\n",
        "best_weights = None\n",
        "# reuse the helper\n",
        "def find_best_weights():\n",
        "    runs = sorted(glob.glob(\"/content/runs/detect/train*\"), key=os.path.getmtime)\n",
        "    for r in reversed(runs):\n",
        "        p = os.path.join(r, \"weights\", \"best.pt\")\n",
        "        if os.path.exists(p):\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "best_weights = find_best_weights()\n",
        "if not best_weights:\n",
        "    print(\"‚ö†Ô∏è Kein best.pt gefunden. Bitte Training laufen lassen.\")\n",
        "else:\n",
        "    source_imgs = os.path.join(DATASET, \"images/test\")\n",
        "    print(\"Predict auf Bildern:\", source_imgs)\n",
        "    if shutil.which(\"yolo\"):\n",
        "        cmd = f\"yolo task=detect mode=predict model='{best_weights}' source='{source_imgs}' imgsz={IMGSZ} conf={CONF} save=True\"\n",
        "        print(\"CLI:\", cmd); os.system(cmd)\n",
        "    else:\n",
        "        model = YOLO(best_weights); model.predict(source=source_imgs, imgsz=IMGSZ, conf=CONF, save=True, verbose=False)\n",
        "\n",
        "    test_videos = sorted(glob.glob(os.path.join(RAW_VIDEOS, \"*\")))\n",
        "    if test_videos:\n",
        "        test_video = test_videos[0]\n",
        "        print(\"Predict auf Video:\", os.path.basename(test_video))\n",
        "        if shutil.which(\"yolo\"):\n",
        "            cmd = f\"yolo task=detect mode=predict model='{best_weights}' source='{test_video}' imgsz={IMGSZ} conf={CONF} vid_stride={VID_STRIDE} save=True\"\n",
        "            print(\"CLI:\", cmd); os.system(cmd)\n",
        "        else:\n",
        "            model = YOLO(best_weights); model.predict(source=test_video, imgsz=IMGSZ, conf=CONF, vid_stride=VID_STRIDE, save=True, verbose=False)\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Kein Video in\", RAW_VIDEOS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£4Ô∏è‚É£ **Tiled Inference** f√ºr 4K‚ÄëVideos\n",
        "Teilt jeden Frame in 640√ó640‚ÄëKacheln, f√ºhrt Detektion pro Kachel durch und fusioniert Ergebnisse (NMS)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tiles_for_shape(w, h, tile, overlap):\n",
        "    stride = int(tile * (1 - overlap))\n",
        "    xs = list(range(0, max(w - tile, 0) + 1, stride))\n",
        "    ys = list(range(0, max(h - tile, 0) + 1, stride))\n",
        "    if xs[-1] != w - tile: xs.append(max(w - tile, 0))\n",
        "    if ys[-1] != h - tile: ys.append(max(h - tile, 0))\n",
        "    return xs, ys\n",
        "\n",
        "def nms_boxes_xyxy(boxes, scores, conf_thr=0.25, iou_thr=0.5):\n",
        "    rects = []\n",
        "    for (x1,y1,x2,y2) in boxes:\n",
        "        rects.append([int(x1), int(y1), int(x2-x1), int(y2-y1)])\n",
        "    idxs = cv2.dnn.NMSBoxes(rects, list(map(float, scores)), conf_thr, iou_thr)\n",
        "    keep = set()\n",
        "    if len(idxs) > 0:\n",
        "        for i in idxs.flatten(): keep.add(i)\n",
        "    return keep\n",
        "\n",
        "def tiled_inference_video(model_path, src_video, dst_video,\n",
        "                          tile=640, overlap=0.2, conf=0.25, iou=0.5):\n",
        "    model = YOLO(model_path)\n",
        "    cap = cv2.VideoCapture(src_video); assert cap.isOpened(), f\"Video nicht ge√∂ffnet: {src_video}\"\n",
        "    w  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)); h  = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps= cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\"); out = cv2.VideoWriter(dst_video, fourcc, fps, (w,h))\n",
        "    xs, ys = tiles_for_shape(w, h, tile, overlap)\n",
        "    from tqdm import tqdm; pbar = tqdm(total=int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0), ncols=100, desc=\"Tiled Inference\")\n",
        "    while True:\n",
        "        ok, frame = cap.read()\n",
        "        if not ok: break\n",
        "        det_boxes, det_scores, det_classes = [], [], []\n",
        "        for y in ys:\n",
        "            for x in xs:\n",
        "                tile_img = frame[y:y+tile, x:x+tile]\n",
        "                res = model.predict(source=tile_img, imgsz=tile, conf=conf, iou=iou, verbose=False)[0]\n",
        "                if res.boxes is None: continue\n",
        "                for b in res.boxes:\n",
        "                    xyxy = b.xyxy[0].cpu().numpy(); x1, y1, x2, y2 = xyxy\n",
        "                    det_boxes.append((x1 + x, y1 + y, x2 + x, y2 + y))\n",
        "                    det_scores.append(float(b.conf[0])); det_classes.append(int(b.cls[0]))\n",
        "        keep = nms_boxes_xyxy(det_boxes, det_scores, conf_thr=conf, iou_thr=iou)\n",
        "        for i in range(len(det_boxes)):\n",
        "            if i not in keep: continue\n",
        "            x1,y1,x2,y2 = map(int, det_boxes[i]); score = det_scores[i]\n",
        "            cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0), 2)\n",
        "            cv2.putText(frame, f\"drone {score:.2f}\", (x1, max(0,y1-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
        "        out.write(frame); pbar.update(1)\n",
        "    pbar.close(); cap.release(); out.release(); print(\"Gespeichert:\", dst_video)\n",
        "\n",
        "best_weights = find_best_weights() if 'find_best_weights' in globals() else None\n",
        "videos = sorted(glob.glob(os.path.join(RAW_VIDEOS, \"*\")))\n",
        "if best_weights and videos:\n",
        "    src = videos[0]\n",
        "    dst = f\"/content/runs/detect/tiled_{os.path.splitext(os.path.basename(src))[0]}.mp4\"\n",
        "    tiled_inference_video(best_weights, src, dst, tile=640, overlap=0.2, conf=0.25, iou=0.5)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Tiled Inference √ºbersprungen (kein best.pt oder kein Video).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£5Ô∏è‚É£ Ergebnisse nach Google Drive sichern\n",
        "Kopiert `best.pt`, Vorhersagen und ggf. `tiled_*.mp4` nach Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs(DRIVE_EXPORT_DIR, exist_ok=True)\n",
        "\n",
        "def copy_if_exists(src_path, dst_dir):\n",
        "    if src_path and os.path.exists(src_path):\n",
        "        dst = os.path.join(dst_dir, os.path.basename(src_path))\n",
        "        shutil.copy2(src_path, dst); print(\"kopiert ‚Üí\", dst)\n",
        "\n",
        "best_weights = find_best_weights() if 'find_best_weights' in globals() else None\n",
        "copy_if_exists(best_weights, DRIVE_EXPORT_DIR)\n",
        "\n",
        "pred_dirs = sorted(glob.glob(\"/content/runs/detect/predict*\"), key=os.path.getmtime)\n",
        "for pd in pred_dirs[-2:]:\n",
        "    dst = os.path.join(DRIVE_EXPORT_DIR, os.path.basename(pd))\n",
        "    if os.path.exists(dst): shutil.rmtree(dst)\n",
        "    shutil.copytree(pd, dst); print(\"kopiert Ordner ‚Üí\", dst)\n",
        "\n",
        "for tv in glob.glob(\"/content/runs/detect/tiled_*.mp4\"):\n",
        "    copy_if_exists(tv, DRIVE_EXPORT_DIR)\n",
        "\n",
        "print(\"‚úÖ Export abgeschlossen. Drive Ordner:\", DRIVE_EXPORT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£6Ô∏è‚É£ (Optional) Umgebung protokollieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"Letzte 50 Pakete:\")\n",
        "!pip freeze | tail -n 50"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Drone_Detection_YOLOv8_Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
